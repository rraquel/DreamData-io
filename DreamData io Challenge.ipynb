{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Procedure:\\n1. load and explore data\\n2. how to define and unite the journey for one costumer\\n3. clean data: drop sessions after user has converted?\\n4. work with a fraction of the dataset\\n5. build dependent variable\\n6. build dummy variables for categorical data\\n7. compare different techniques and sampeling methods\\n8. build final cross validated predictive model\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### DreamData.io \n",
    "\n",
    "\"\"\"Challenge: The task of this code challenge is to predict if a conversion (e.g. form\n",
    "submission) would happen in or right after each session in the whole customer\n",
    "journey. A conversion in this context means a user signs up so that the company\n",
    "gets his contact information. A whole customer journey might contain one or\n",
    "multiple sessions.\"\"\"\n",
    "\n",
    "\"\"\" Procedure:\n",
    "1. load and explore data\n",
    "2. how to define and unite the journey for one costumer?\n",
    "3. clean data: drop sessions after user has converted?\n",
    "4. work with a fraction of the dataset\n",
    "5. build dependent variable\n",
    "6. build dummy variables for categorical data\n",
    "7. compare different techniques and sampeling methods\n",
    "8. build final cross validated predictive model\n",
    "\n",
    "class imbalance is too big for sampling:\n",
    "next steps would be to clean the dataset further, to build journeys for each costumer\n",
    "and to discuss which other problems may exist inherent to the type of data and how these can be adressed\n",
    "\n",
    "After that, it would be interesting to look at other techniques, more specific to this kind of problem: maybe markov-chain models etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2366475\n",
       "True       39679\n",
       "Name: conversion, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Setup\n",
    "\n",
    "# load data into pd\n",
    "df_original = pd.read_csv(\"training_data.csv\") \n",
    "\n",
    "df_original.shape\n",
    "\n",
    "#df_original.isna().sum()\n",
    "\n",
    "\n",
    "# preview the first 5 lines of data \n",
    "#df.head()\n",
    "\n",
    "#Column types\n",
    "#df_original.dtypes\n",
    "\n",
    "#changing data types takes to long, because the dataset is big. Therefore we will work with a sample first\n",
    "#pd.to_datetime(df_original.conversion_time)\n",
    "#pd.to_datetime(df_original.session_end_time)\n",
    "#pd.to_datetime(df_original.session_start_time)\n",
    "#pd.to_datetime(df_original.later_session_start_time)\n",
    "\n",
    "# Conversion counts\n",
    "df_original['conversion'].value_counts()\n",
    "\n",
    "#check that there is only true or false in the conversion counts\n",
    "#df.conversion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    591785\n",
       "True       9753\n",
       "Name: conversion, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract a random sample to work with 25% of the data only - otherwise the processes take too long\n",
    "df=df_original.sample(frac=0.25, random_state=1)\n",
    "# Conversion counts\n",
    "df['conversion'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597784, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take each user with conversion=true and drop all the sessions after the conversion, as they are not relevant instances for solving the prediction problem\n",
    "# takes way to long if it is done beofer sampling.....\n",
    "user_ids_conv=df['user_id']\n",
    "df_conv=df[df['conversion']==True]\n",
    "user_ids_conv=df_conv['user_id']\n",
    "\n",
    "\n",
    "for user in user_ids_conv:\n",
    "    df.drop(df[(df['user_id']== user) & (df['conversion_time'] < df['session_start_time'])].index, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597784, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the data into csv, to be loaded directly\n",
    "#df.to_csv(r'training_data_sampled_journey.csv', index = False)\n",
    "df_original = pd.read_csv(\"training_data_sampled_journey.csv\") \n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at duplicate user_id s\n",
    "#dupl_user = df.pivot_table(index=['user_id'], aggfunc='size')\n",
    "#print (dupl_user)\n",
    "\n",
    "#********************* look into how to compose one journey which may contain multiple sessions************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversion                      bool\n",
       "conversion_time               object\n",
       "user_id                        int64\n",
       "sessionId                      int64\n",
       "minutes_since_last_session     int64\n",
       "event                         object\n",
       "browser                       object\n",
       "os                            object\n",
       "device                        object\n",
       "channel                       object\n",
       "session_end_time              object\n",
       "session_start_time            object\n",
       "event_count                    int64\n",
       "country                       object\n",
       "session_duration_seconds       int64\n",
       "later_session_start_time      object\n",
       "region                        object\n",
       "sub_region                    object\n",
       "source                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tpes of columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column with the dependent variable\n",
    "df['dependent_variable'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    597784.000000\n",
      "mean       3507.106256\n",
      "std       16735.994541\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%          56.000000\n",
      "max      369575.000000\n",
      "Name: minutes_since_last_session, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x183273f6c08>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"#look if conversion_time is after end of session\n",
    "#create a new column for conversion after session with time delta\n",
    "df['conversion_after_end'] = pd.to_datetime(df['conversion_time']) - pd.to_datetime(df['session_end_time'])\n",
    "#df['conversion_after_end'].value_counts()\n",
    "df.head(100)\n",
    "\n",
    "--> can use minutes_since_last_session!!!\"\"\"\n",
    "print(df['minutes_since_last_session'].describe())\n",
    "sns.distplot(df['minutes_since_last_session'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    591785\n",
       "1      5999\n",
       "Name: dependent_variable, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert dependent_variable value 1 if the conversion occcurred within the session\n",
    "df.loc[(df['conversion_time'] < (df['session_end_time'])) & (df['conversion_time'] > df['session_start_time']), 'dependent_variable'] = 1\n",
    "df['dependent_variable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    591785\n",
       "1      5999\n",
       "Name: dependent_variable, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#insert dependent_variable value 1 if the conversion occcurred right after the end of the session (max. 30 minutes)\n",
    "df.loc[(df['minutes_since_last_session'] < 59) & (df['conversion'] == True), 'dependent_variable'] = 1\n",
    "df['dependent_variable'].value_counts()\n",
    "# positive exaples ~1.5%\n",
    "\n",
    "#### THE DATASET IS HIGHLY UNBALANCED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18354a5dc08>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize class distribution of dependent variable --> highly imbalanced data\n",
    "sns.countplot(df['dependent_variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conversion' 'conversion_time' 'user_id' 'sessionId'\n",
      " 'minutes_since_last_session' 'event' 'browser' 'os' 'device' 'channel'\n",
      " 'session_end_time' 'session_start_time' 'event_count' 'country'\n",
      " 'session_duration_seconds' 'later_session_start_time' 'region'\n",
      " 'sub_region' 'source' 'dependent_variable']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dependent_variable</th>\n",
       "      <th>event</th>\n",
       "      <th>browser</th>\n",
       "      <th>os</th>\n",
       "      <th>device</th>\n",
       "      <th>channel</th>\n",
       "      <th>minutes_since_last_session</th>\n",
       "      <th>event_count</th>\n",
       "      <th>session_duration_seconds</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416985</th>\n",
       "      <td>0</td>\n",
       "      <td>page_view</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>direct</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>541</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172060</th>\n",
       "      <td>0</td>\n",
       "      <td>page_view</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Android</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>Paid</td>\n",
       "      <td>20160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309822</th>\n",
       "      <td>0</td>\n",
       "      <td>page_view</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Windows</td>\n",
       "      <td>DESKTOP</td>\n",
       "      <td>referrer</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>referrer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788632</th>\n",
       "      <td>0</td>\n",
       "      <td>page_view</td>\n",
       "      <td>Safari</td>\n",
       "      <td>iOS</td>\n",
       "      <td>TABLET</td>\n",
       "      <td>Paid</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835362</th>\n",
       "      <td>0</td>\n",
       "      <td>page_view</td>\n",
       "      <td>Webkit based browser</td>\n",
       "      <td>iOS</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Social</td>\n",
       "      <td>112900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LinkedIn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dependent_variable      event               browser       os  \\\n",
       "416985                    0  page_view                Chrome  Windows   \n",
       "172060                    0  page_view                Chrome  Android   \n",
       "2309822                   0  page_view                Chrome  Windows   \n",
       "788632                    0  page_view                Safari      iOS   \n",
       "835362                    0  page_view  Webkit based browser      iOS   \n",
       "\n",
       "          device   channel  minutes_since_last_session  event_count  \\\n",
       "416985   DESKTOP    direct                           4           20   \n",
       "172060    TABLET      Paid                       20160            1   \n",
       "2309822  DESKTOP  referrer                         121            3   \n",
       "788632    TABLET      Paid                         101            1   \n",
       "835362    MOBILE    Social                      112900            1   \n",
       "\n",
       "         session_duration_seconds    source  \n",
       "416985                        541    direct  \n",
       "172060                          0    Google  \n",
       "2309822                        12  referrer  \n",
       "788632                          0    Google  \n",
       "835362                          0  LinkedIn  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset for prediction\n",
    "\n",
    "df_data = df[['dependent_variable', 'event', 'browser', 'os', 'device', \n",
    "              'channel', 'minutes_since_last_session', 'event_count', 'session_duration_seconds', 'source']]\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for l in ['event', 'browser', 'os', 'device', \\n              'channel','source']:\\n    print(l)\\n    print(df_data[l].value_counts())\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look into categorical data to create dummy variables\n",
    "\"\"\"for l in ['event', 'browser', 'os', 'device', \n",
    "              'channel','source']:\n",
    "    print(l)\n",
    "    print(df_data[l].value_counts())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dependent_variable' 'event' 'browser' 'os' 'device' 'channel'\n",
      " 'minutes_since_last_session' 'event_count' 'session_duration_seconds'\n",
      " 'source' 'source_Ask.com' 'source_Baidu' 'source_Banners' 'source_Bing'\n",
      " 'source_Caspari' 'source_DIS' 'source_DMP' 'source_Display'\n",
      " 'source_DuckDuckGo' 'source_Ecosia' 'source_Email' 'source_Facebook'\n",
      " 'source_Google' 'source_Instagram' 'source_Kragen' 'source_LinkedIn'\n",
      " 'source_MGWW' 'source_Marketing Vendor' 'source_Must See Promo'\n",
      " 'source_MyWay' 'source_Naver' 'source_Newsletter Ad' 'source_Others'\n",
      " 'source_Outlook' 'source_Paid Media' 'source_Pinterest'\n",
      " 'source_Programmatic' 'source_RTB' 'source_Reddit' 'source_Slack'\n",
      " 'source_SoMe' 'source_Twitter' 'source_Xing' 'source_YJP' 'source_Yahoo'\n",
      " 'source_Yandex' 'source_Youtube' 'source_blog' 'source_direct'\n",
      " 'source_eblast' 'source_ebooks' 'source_hs_automation'\n",
      " 'source_organic_social_media' 'source_outbound' 'source_referrer'\n",
      " 'source_sendinblue' 'source_sniply' 'source_vkontakte' 'source_wechat'\n",
      " 'source_whippany']\n"
     ]
    }
   ],
   "source": [
    "#create dummy values for categorical variables\n",
    "#should look into this more carefully and create a variable for 'others' when the value counts for a category is low\n",
    "categorical_variables=['event', 'browser', 'os', 'device', \n",
    "              'channel','source']\n",
    "for item in categorical_variables:\n",
    "    dummies = pd.get_dummies(df_data[item]).rename(columns=lambda x: item+ '_' + str(x))\n",
    "    df_data_new = pd.concat([df_data, dummies], axis=1)\n",
    "    #df_data_new = df_data_new.drop(item) --why does that not work?\n",
    "print(df_data_new.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dependent_variable</th>\n",
       "      <th>minutes_since_last_session</th>\n",
       "      <th>event_count</th>\n",
       "      <th>session_duration_seconds</th>\n",
       "      <th>source_Ask.com</th>\n",
       "      <th>source_Baidu</th>\n",
       "      <th>source_Banners</th>\n",
       "      <th>source_Bing</th>\n",
       "      <th>source_Caspari</th>\n",
       "      <th>source_DIS</th>\n",
       "      <th>...</th>\n",
       "      <th>source_ebooks</th>\n",
       "      <th>source_hs_automation</th>\n",
       "      <th>source_organic_social_media</th>\n",
       "      <th>source_outbound</th>\n",
       "      <th>source_referrer</th>\n",
       "      <th>source_sendinblue</th>\n",
       "      <th>source_sniply</th>\n",
       "      <th>source_vkontakte</th>\n",
       "      <th>source_wechat</th>\n",
       "      <th>source_whippany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416985</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172060</th>\n",
       "      <td>0</td>\n",
       "      <td>20160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309822</th>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788632</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835362</th>\n",
       "      <td>0</td>\n",
       "      <td>112900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dependent_variable  minutes_since_last_session  event_count  \\\n",
       "416985                    0                           4           20   \n",
       "172060                    0                       20160            1   \n",
       "2309822                   0                         121            3   \n",
       "788632                    0                         101            1   \n",
       "835362                    0                      112900            1   \n",
       "\n",
       "         session_duration_seconds  source_Ask.com  source_Baidu  \\\n",
       "416985                        541               0             0   \n",
       "172060                          0               0             0   \n",
       "2309822                        12               0             0   \n",
       "788632                          0               0             0   \n",
       "835362                          0               0             0   \n",
       "\n",
       "         source_Banners  source_Bing  source_Caspari  source_DIS  ...  \\\n",
       "416985                0            0               0           0  ...   \n",
       "172060                0            0               0           0  ...   \n",
       "2309822               0            0               0           0  ...   \n",
       "788632                0            0               0           0  ...   \n",
       "835362                0            0               0           0  ...   \n",
       "\n",
       "         source_ebooks  source_hs_automation  source_organic_social_media  \\\n",
       "416985               0                     0                            0   \n",
       "172060               0                     0                            0   \n",
       "2309822              0                     0                            0   \n",
       "788632               0                     0                            0   \n",
       "835362               0                     0                            0   \n",
       "\n",
       "         source_outbound  source_referrer  source_sendinblue  source_sniply  \\\n",
       "416985                 0                0                  0              0   \n",
       "172060                 0                0                  0              0   \n",
       "2309822                0                1                  0              0   \n",
       "788632                 0                0                  0              0   \n",
       "835362                 0                0                  0              0   \n",
       "\n",
       "         source_vkontakte  source_wechat  source_whippany  \n",
       "416985                  0              0                0  \n",
       "172060                  0              0                0  \n",
       "2309822                 0              0                0  \n",
       "788632                  0              0                0  \n",
       "835362                  0              0                0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the original categorical variables and show new data frame\n",
    "for var in categorical_variables:\n",
    "    df_data_new= df_data_new.drop(var, axis=1)\n",
    "df_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test\n",
    "X = df_data_new.drop('dependent_variable', axis = 1) \n",
    "y = df_data_new['dependent_variable']\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#scale the data - does not seem necessary\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#feature_scaler = StandardScaler()\n",
    "#X_train = feature_scaler.fit_transform(X_train)\n",
    "#X_test = feature_scaler.transform(X_test)\n",
    "\n",
    "#Do not perform feature selections as the number of features is low and they all seem relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597784, 53)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Training set score: \", model.score(X_train, y_train))\n",
    "    print(\"Test set score: \", model.score(X_test, y_test))\n",
    "    #print the predictions\n",
    "    #print(predictions)\n",
    "    #Check precision, recall, f1-score\n",
    "    print( classification_report(y_test, predictions))\n",
    "    return (predictions, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try different ML models\n",
    "def buildmodels():\n",
    "\n",
    "    #logistic regression\n",
    "    print(\"Logistic Regression\")\n",
    "    logreg = LogisticRegression()\n",
    "    logreg_pred, logreg=classify(logreg)\n",
    "\n",
    "    #LinearSVC\n",
    "    print(\"LinearSCV\")\n",
    "    lsvc = LinearSVC()\n",
    "    lsv_pred, lsvc=classify(lsvc)\n",
    "\n",
    "    #decision tree\n",
    "    print(\"Decision Tree Cl\")\n",
    "    tree=DecisionTreeClassifier()\n",
    "    tree_pred, tree=classify(tree)\n",
    "    #print(\"feature imporatnces\", tree.feature_importances_)\n",
    "\n",
    "    #random forest\n",
    "    print(\"Radnom Forest Cl\")\n",
    "    forest=RandomForestClassifier()\n",
    "    forest_pred, forest=classify(forest)\n",
    "    #print(\"feature imporatnces\", forest.feature_importances_)\n",
    "\n",
    "    #gradient boosting\n",
    "    print(\"Gradient Boosting Cl\")\n",
    "    gbrt=GradientBoostingClassifier()\n",
    "    gbrt_pred, gbrt=classify(gbrt)\n",
    "\n",
    "    #MNeural Networks: MLPs\n",
    "    print(\"MLP\")\n",
    "    mlp=MLPClassifier()\n",
    "    mlp_pred, mlp=classify(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training set score:  0.9896283564081493\n",
      "Test set score:  0.98953637177246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    118344\n",
      "           1       0.15      0.01      0.01      1213\n",
      "\n",
      "    accuracy                           0.99    119557\n",
      "   macro avg       0.57      0.50      0.50    119557\n",
      "weighted avg       0.98      0.99      0.98    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9862722096410282\n",
      "Test set score:  0.9861739588648093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    118344\n",
      "           1       0.05      0.02      0.03      1213\n",
      "\n",
      "    accuracy                           0.99    119557\n",
      "   macro avg       0.52      0.51      0.51    119557\n",
      "weighted avg       0.98      0.99      0.98    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9977500224788647\n",
      "Test set score:  0.982343150129227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    118344\n",
      "           1       0.09      0.08      0.08      1213\n",
      "\n",
      "    accuracy                           0.98    119557\n",
      "   macro avg       0.54      0.53      0.54    119557\n",
      "weighted avg       0.98      0.98      0.98    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9977291119071069\n",
      "Test set score:  0.987629331615882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    118344\n",
      "           1       0.12      0.03      0.05      1213\n",
      "\n",
      "    accuracy                           0.99    119557\n",
      "   macro avg       0.55      0.52      0.52    119557\n",
      "weighted avg       0.98      0.99      0.98    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.990015201985668\n",
      "Test set score:  0.9898542117985564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    118344\n",
      "           1       0.00      0.00      0.00      1213\n",
      "\n",
      "    accuracy                           0.99    119557\n",
      "   macro avg       0.49      0.50      0.50    119557\n",
      "weighted avg       0.98      0.99      0.98    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9899922003567344\n",
      "Test set score:  0.9898542117985564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    118344\n",
      "           1       0.00      0.00      0.00      1213\n",
      "\n",
      "    accuracy                           0.99    119557\n",
      "   macro avg       0.49      0.50      0.50    119557\n",
      "weighted avg       0.98      0.99      0.98    119557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buildmodels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearMiss(n_jobs=None, n_neighbors=3, n_neighbors_ver3=3,\n",
      "         sampling_strategy='auto', version=1)\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9419139155871291\n",
      "Test set score:  0.6165929222044715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76    118344\n",
      "           1       0.02      0.91      0.05      1213\n",
      "\n",
      "    accuracy                           0.62    119557\n",
      "   macro avg       0.51      0.76      0.40    119557\n",
      "weighted avg       0.99      0.62      0.75    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9184078562473882\n",
      "Test set score:  0.5354182523817091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69    118344\n",
      "           1       0.02      0.87      0.04      1213\n",
      "\n",
      "    accuracy                           0.54    119557\n",
      "   macro avg       0.51      0.70      0.37    119557\n",
      "weighted avg       0.99      0.54      0.69    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9692854157960719\n",
      "Test set score:  0.44124559833384913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61    118344\n",
      "           1       0.02      0.95      0.03      1213\n",
      "\n",
      "    accuracy                           0.44    119557\n",
      "   macro avg       0.51      0.69      0.32    119557\n",
      "weighted avg       0.99      0.44      0.60    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9692854157960719\n",
      "Test set score:  0.06087472920866198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.05      0.10    118344\n",
      "           1       0.01      0.95      0.02      1213\n",
      "\n",
      "    accuracy                           0.06    119557\n",
      "   macro avg       0.50      0.50      0.06    119557\n",
      "weighted avg       0.98      0.06      0.10    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.950793982448809\n",
      "Test set score:  0.5790543422802512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.72    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9451525282072712\n",
      "Test set score:  0.5740860008196927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73    118344\n",
      "           1       0.02      0.92      0.04      1213\n",
      "\n",
      "    accuracy                           0.57    119557\n",
      "   macro avg       0.51      0.75      0.38    119557\n",
      "weighted avg       0.99      0.57      0.72    119557\n",
      "\n",
      "RandomUnderSampler(random_state=None, replacement=False,\n",
      "                   sampling_strategy='auto')\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9419139155871291\n",
      "Test set score:  0.6165678295708323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76    118344\n",
      "           1       0.02      0.92      0.05      1213\n",
      "\n",
      "    accuracy                           0.62    119557\n",
      "   macro avg       0.51      0.76      0.40    119557\n",
      "weighted avg       0.99      0.62      0.75    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.916213957375679\n",
      "Test set score:  0.5458484237643969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70    118344\n",
      "           1       0.02      0.85      0.04      1213\n",
      "\n",
      "    accuracy                           0.55    119557\n",
      "   macro avg       0.51      0.70      0.37    119557\n",
      "weighted avg       0.99      0.55      0.70    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9692854157960719\n",
      "Test set score:  0.4408022951395569\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61    118344\n",
      "           1       0.02      0.95      0.03      1213\n",
      "\n",
      "    accuracy                           0.44    119557\n",
      "   macro avg       0.51      0.69      0.32    119557\n",
      "weighted avg       0.99      0.44      0.60    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9692854157960719\n",
      "Test set score:  0.06671294863537894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.06      0.11    118344\n",
      "           1       0.01      0.95      0.02      1213\n",
      "\n",
      "    accuracy                           0.07    119557\n",
      "   macro avg       0.50      0.50      0.06    119557\n",
      "weighted avg       0.98      0.07      0.11    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.950793982448809\n",
      "Test set score:  0.5792634475605778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.72    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.942227329711659\n",
      "Test set score:  0.6042724390876318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75    118344\n",
      "           1       0.02      0.92      0.05      1213\n",
      "\n",
      "    accuracy                           0.60    119557\n",
      "   macro avg       0.51      0.76      0.40    119557\n",
      "weighted avg       0.99      0.60      0.74    119557\n",
      "\n",
      "AllKNN(allow_minority=False, kind_sel='all', n_jobs=None, n_neighbors=3,\n",
      "       sampling_strategy='auto')\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9697101765090433\n",
      "Test set score:  0.6258939250733959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    118344\n",
      "           1       0.02      0.90      0.05      1213\n",
      "\n",
      "    accuracy                           0.63    119557\n",
      "   macro avg       0.51      0.76      0.41    119557\n",
      "weighted avg       0.99      0.63      0.76    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9588145565482676\n",
      "Test set score:  0.603753857992422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75    118344\n",
      "           1       0.02      0.87      0.04      1213\n",
      "\n",
      "    accuracy                           0.60    119557\n",
      "   macro avg       0.51      0.73      0.40    119557\n",
      "weighted avg       0.99      0.60      0.74    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9955327958160819\n",
      "Test set score:  0.581597062489022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.73    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9955327958160819\n",
      "Test set score:  0.21092867837098622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.34    118344\n",
      "           1       0.01      0.94      0.02      1213\n",
      "\n",
      "    accuracy                           0.21    119557\n",
      "   macro avg       0.50      0.57      0.18    119557\n",
      "weighted avg       0.99      0.21      0.33    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.9775550228808019\n",
      "Test set score:  0.5496457756551268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71    118344\n",
      "           1       0.02      0.92      0.04      1213\n",
      "\n",
      "    accuracy                           0.55    119557\n",
      "   macro avg       0.51      0.73      0.37    119557\n",
      "weighted avg       0.99      0.55      0.70    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9681847897145348\n",
      "Test set score:  0.6232926553861338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    118344\n",
      "           1       0.02      0.89      0.05      1213\n",
      "\n",
      "    accuracy                           0.62    119557\n",
      "   macro avg       0.51      0.76      0.41    119557\n",
      "weighted avg       0.99      0.62      0.76    119557\n",
      "\n",
      "RandomOverSampler(random_state=None, sampling_strategy='auto')\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9683451734224823\n",
      "Test set score:  0.6261615798322139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    118344\n",
      "           1       0.02      0.90      0.05      1213\n",
      "\n",
      "    accuracy                           0.63    119557\n",
      "   macro avg       0.51      0.76      0.41    119557\n",
      "weighted avg       0.99      0.63      0.76    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9657333890513999\n",
      "Test set score:  0.5950132572747727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.59      0.74    118344\n",
      "           1       0.02      0.90      0.04      1213\n",
      "\n",
      "    accuracy                           0.60    119557\n",
      "   macro avg       0.51      0.75      0.39    119557\n",
      "weighted avg       0.99      0.60      0.74    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9950898453823652\n",
      "Test set score:  0.5815134203768914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.73    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.994985374007522\n",
      "Test set score:  0.21786260946661426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.35    118344\n",
      "           1       0.01      0.94      0.02      1213\n",
      "\n",
      "    accuracy                           0.22    119557\n",
      "   macro avg       0.50      0.57      0.19    119557\n",
      "weighted avg       0.99      0.22      0.34    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.9780610112829085\n",
      "Test set score:  0.5511764263071172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71    118344\n",
      "           1       0.02      0.92      0.04      1213\n",
      "\n",
      "    accuracy                           0.55    119557\n",
      "   macro avg       0.51      0.73      0.37    119557\n",
      "weighted avg       0.99      0.55      0.70    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9727329711659005\n",
      "Test set score:  0.6113234691402427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76    118344\n",
      "           1       0.02      0.91      0.05      1213\n",
      "\n",
      "    accuracy                           0.61    119557\n",
      "   macro avg       0.51      0.76      0.40    119557\n",
      "weighted avg       0.99      0.61      0.75    119557\n",
      "\n",
      "SMOTE(k_neighbors=5, n_jobs=None, random_state=None, sampling_strategy='auto')\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9683451734224823\n",
      "Test set score:  0.6261615798322139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    118344\n",
      "           1       0.02      0.90      0.05      1213\n",
      "\n",
      "    accuracy                           0.63    119557\n",
      "   macro avg       0.51      0.76      0.41    119557\n",
      "weighted avg       0.99      0.63      0.76    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9642707898035938\n",
      "Test set score:  0.5849511111854596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.75      0.39    119557\n",
      "weighted avg       0.99      0.58      0.73    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9950898453823652\n",
      "Test set score:  0.5815803340665958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.73    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9950898453823652\n",
      "Test set score:  0.22291459303930342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.35    118344\n",
      "           1       0.01      0.94      0.02      1213\n",
      "\n",
      "    accuracy                           0.22    119557\n",
      "   macro avg       0.50      0.58      0.19    119557\n",
      "weighted avg       0.99      0.22      0.35    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.9780610112829085\n",
      "Test set score:  0.5511764263071172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71    118344\n",
      "           1       0.02      0.92      0.04      1213\n",
      "\n",
      "    accuracy                           0.55    119557\n",
      "   macro avg       0.51      0.73      0.37    119557\n",
      "weighted avg       0.99      0.55      0.70    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9692854157960719\n",
      "Test set score:  0.6208252130782806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.76    118344\n",
      "           1       0.02      0.89      0.05      1213\n",
      "\n",
      "    accuracy                           0.62    119557\n",
      "   macro avg       0.51      0.76      0.40    119557\n",
      "weighted avg       0.99      0.62      0.76    119557\n",
      "\n",
      "KMeansSMOTE(cluster_balance_threshold='auto', density_exponent='auto',\n",
      "            k_neighbors=2, kmeans_estimator=None, n_jobs=None,\n",
      "            random_state=None, sampling_strategy='auto')\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9683451734224823\n",
      "Test set score:  0.6261615798322139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.77    118344\n",
      "           1       0.02      0.90      0.05      1213\n",
      "\n",
      "    accuracy                           0.63    119557\n",
      "   macro avg       0.51      0.76      0.41    119557\n",
      "weighted avg       0.99      0.63      0.76    119557\n",
      "\n",
      "LinearSCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rraquel\\.conda\\envs\\amb_env\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score:  0.9619724195570414\n",
      "Test set score:  0.601436971486404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75    118344\n",
      "           1       0.02      0.88      0.04      1213\n",
      "\n",
      "    accuracy                           0.60    119557\n",
      "   macro avg       0.51      0.74      0.40    119557\n",
      "weighted avg       0.99      0.60      0.74    119557\n",
      "\n",
      "Decision Tree Cl\n",
      "Training set score:  0.9950898453823652\n",
      "Test set score:  0.5815301487993175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    118344\n",
      "           1       0.02      0.93      0.04      1213\n",
      "\n",
      "    accuracy                           0.58    119557\n",
      "   macro avg       0.51      0.76      0.39    119557\n",
      "weighted avg       0.99      0.58      0.73    119557\n",
      "\n",
      "Radnom Forest Cl\n",
      "Training set score:  0.9950898453823652\n",
      "Test set score:  0.22800003345684486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36    118344\n",
      "           1       0.01      0.94      0.02      1213\n",
      "\n",
      "    accuracy                           0.23    119557\n",
      "   macro avg       0.50      0.58      0.19    119557\n",
      "weighted avg       0.99      0.23      0.36    119557\n",
      "\n",
      "Gradient Boosting Cl\n",
      "Training set score:  0.9780610112829085\n",
      "Test set score:  0.5511764263071172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71    118344\n",
      "           1       0.02      0.92      0.04      1213\n",
      "\n",
      "    accuracy                           0.55    119557\n",
      "   macro avg       0.51      0.73      0.37    119557\n",
      "weighted avg       0.99      0.55      0.70    119557\n",
      "\n",
      "MLP\n",
      "Training set score:  0.9687630589218554\n",
      "Test set score:  0.6152546484103817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.61      0.76    118344\n",
      "           1       0.02      0.89      0.04      1213\n",
      "\n",
      "    accuracy                           0.62    119557\n",
      "   macro avg       0.51      0.75      0.40    119557\n",
      "weighted avg       0.99      0.62      0.75    119557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### WEIGHT CLASSES TO CHECK IF THE PERFORMANCE CAN BE IMPORVED\n",
    "#try different sampling methods\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import AllKNN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "\n",
    "for method in [NearMiss(version=1), RandomUnderSampler(), AllKNN(), RandomOverSampler(), SMOTE(), KMeansSMOTE()]:\n",
    "    X_res, y_res = method.fit_resample(X_train, y_train)\n",
    "    X_train, y_train=X_res, y_res\n",
    "    print(method)\n",
    "    buildmodels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class imbalance seems still to high, even after sampling.\n",
    "#It would be better to work on the dataset, to see if costumer journeys can be united for each user and then go back to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No clusters found with sufficient samples of class 1. Try lowering the cluster_balance_threshold or increasing the number of clusters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-3ac180410c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#random under sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\amb_env\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (label_binarize(output[1], np.unique(y))\n",
      "\u001b[1;32m~\\.conda\\envs\\amb_env\\lib\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1258\u001b[0m                     \u001b[1;34m\"class {}. Try lowering the cluster_balance_threshold \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m                     \u001b[1;34m\"or increasing the number of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1260\u001b[1;33m                     \u001b[1;34m\"clusters.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1261\u001b[0m                 )\n\u001b[0;32m   1262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No clusters found with sufficient samples of class 1. Try lowering the cluster_balance_threshold or increasing the number of clusters."
     ]
    }
   ],
   "source": [
    "# build cross validated model for best performing technique\n",
    "# scoring should be recall, as we want to predict the converted.\n",
    "\n",
    "#model chosen: decision tree with random under sampling\n",
    "\n",
    "#random under sampling\n",
    "RandomUnderSampler()\n",
    "X_res, y_res = method.fit_resample(X, y)\n",
    "X, y=X_res, y_res\n",
    "\n",
    "#Final model to predict out of sample with complete dataset, 5-fold CV and recall scoring\n",
    "\n",
    "depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "weight = ['balanced', None]\n",
    "criterion = ['gini', 'entropy']\n",
    "tree_param_grid = {'max_depth': depth, 'class_weight': weight, 'criterion': criterion}\n",
    "\n",
    "tree_grid_search = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, cv=5, scoring='recall',\n",
    "                                return_train_score=True)\n",
    "\n",
    "tree_grid_search.fit(X, y)\n",
    "print(tree_grid_search.best_params_)\n",
    "print(\"Best cross-val score: {:.2f}\".format(tree_grid_search.best_score_))\n",
    "print(\"Best estimator: \\n {}\".format(tree_grid_search.best_estimator_))\n",
    "print(\"Recall on training set: {:.3f}\".format(tree_grid_search.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
